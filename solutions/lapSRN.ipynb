{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.functional as F\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import psutil\n",
    "from util import format\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datasets import DeepLenseSuperresolutionDataset\n",
    "import matplotlib.pyplot as plt \n",
    "from torchinfo import summary\n",
    "from util import MSE_Metric, PSNR_Metric, SSIM_Metric\n",
    "import math\n",
    "\n",
    "# PyTorch imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CONFIG:\n",
    "    BATCH_SIZE = 4\n",
    "    \n",
    "    # limit the data to prototype faster\n",
    "    DATA_LIMIT = 200\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    ROUND_NUMBER = 3\n",
    "    TASK_NAME = \"DeepLense2024_task2A\"\n",
    "    DATA_PATH = os.path.join(\"Data\", \"Superresolution\")\n",
    "    PORTION_OF_DATA_FOR_TRAINING = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLenseSuperresolutionDatasetLapSRN(Dataset):\n",
    "\n",
    "    def __init__(self, folder_path : str,\n",
    "                 randomize_dataset : bool = True,\n",
    "                 preprocess_LR : bool = True, \n",
    "                 preprocess_HR : bool = True,\n",
    "                 call_preprocess : bool = True,\n",
    "                 data_limit=0, \n",
    "                 mean_LR = None, std_LR=None, \n",
    "                 mean_HR=None, std_HR=None) -> None:\n",
    "        \n",
    "        self.folder_path = folder_path\n",
    "        self.class_folders = []\n",
    "        self.preprocess_LR = preprocess_LR\n",
    "        self.preprocess_HR = preprocess_HR\n",
    "\n",
    "        folders = [os.path.join(self.folder_path, v) for v in os.listdir(folder_path)]\n",
    "\n",
    "        self.LR = [v for v in folders if v.endswith(\"LR\")][0]\n",
    "        self.HR = [v for v in folders if v.endswith(\"HR\")][0]\n",
    "\n",
    "        self.class_folders = [self.LR, self.HR]\n",
    "        \n",
    "        print(self.LR, self.HR)\n",
    "        assert os.listdir(self.LR) == os.listdir(self.HR), \"the number of samples in Low Resolution has to be the same as High Resolution\"\n",
    "\n",
    "        # get the samples \n",
    "        self.samples = os.listdir(self.LR)\n",
    "        \n",
    "        # limit the data (for faster prototyping )\n",
    "        if data_limit > 0:\n",
    "            self.samples = self.samples[:data_limit]\n",
    "                \n",
    "        # Datapoints\n",
    "        self.LR_data = []\n",
    "        self.HR_data = []\n",
    "            \n",
    "        pbar = tqdm(self.samples)\n",
    "        for path in pbar:\n",
    "            # load from the low resolution\n",
    "            img1 = np.load(os.path.join(self.LR, path))\n",
    "            self.LR_data.append(torch.Tensor(img1))            \n",
    "            \n",
    "            # load from the high resolution\n",
    "            img2 = np.load(os.path.join(self.HR, path))\n",
    "            self.HR_data.append(torch.Tensor(img2))\n",
    "            \n",
    "            pbar.set_description(\"Loading dataset : \")\n",
    "        \n",
    "        self.samples = np.array(self.samples)\n",
    "        self.LR_data = torch.stack(self.LR_data)\n",
    "        self.HR_data = torch.stack(self.HR_data)\n",
    "        \n",
    "        if randomize_dataset:\n",
    "            self.randomize_dataset()\n",
    "        \n",
    "        \n",
    "    # To override later (if any preprocessing is required)\n",
    "    def preprocess_LR_func(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        return x\n",
    "        \n",
    "    def preprocess_HR_func(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        return x\n",
    "        \n",
    "    def randomize_dataset(self):\n",
    "        idxes = np.arange(len(self.LR_data))\n",
    "        random.shuffle(idxes)\n",
    "\n",
    "        self.samples = self.samples[idxes]\n",
    "        self.LR_data = self.LR_data[idxes]\n",
    "        self.HR_data = self.HR_data[idxes]\n",
    "    \n",
    "    def preprocess_input(self, x : np.ndarray) -> torch.Tensor:\n",
    "        return torch.tensor( (x - self.mean) / self.std).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.LR_data[idx], self.HR_data[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task2(model : nn.Module, val_dataset : DataLoader, cfg : CONFIG, metrics : List[Metric], test_params : Dict[str, int] = {\"save_in_total\" : None, \"save_every\" : 0} ,  run = None):        \n",
    "    # change the model to evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # get the number of datapoints\n",
    "    number_of_datapoints = len(val_dataset.dataset)    \n",
    "\n",
    "    # allocate the memory for these datapoints (no need to keep appending the data, which will make it slower)\n",
    "    metrics_names = [metric.name for metric in metrics]\n",
    "    metrics_vals = np.zeros((number_of_datapoints, len(metrics_names)))\n",
    "\n",
    "    save_images_every = 0\n",
    "    if \"save_in_total\" in test_params and test_params[\"save_in_total\"] is not None and test_params[\"save_in_total\"] > 0:\n",
    "        save_images_every = number_of_datapoints // test_params[\"save_in_total\"]\n",
    "        \n",
    "    elif \"save_every\" in test_params:\n",
    "        save_images_every = test_params[\"save_every\"]\n",
    "\n",
    "    if save_images_every > 0:\n",
    "        shape = val_dataset.dataset[0][1].shape\n",
    "        \n",
    "        saved_images_pred = np.zeros((number_of_datapoints // save_images_every, shape[1], shape[2], shape[0]))\n",
    "        saved_images_true = np.zeros((number_of_datapoints // save_images_every, shape[1], shape[2], shape[0]))\n",
    "        img_c = 0\n",
    "    \n",
    "    # get the number of batches\n",
    "    dataset_len = len(val_dataset)\n",
    "\n",
    "    # create the progreess bar \n",
    "    pbar = tqdm(val_dataset)\n",
    "\n",
    "    # variable that will track where we are in terms of all data (after iteration add batch size to it)\n",
    "    c = 0\n",
    "    for i, (x,y) in enumerate(pbar): \n",
    "        # get the predictions\n",
    "        pred = model(x.to(CONFIG.DEVICE))\n",
    "        y = y.to(CONFIG.DEVICE)\n",
    " \n",
    "        # get the batch size\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        # calculate the metric for every image in the batch:\n",
    "        for img_i in range(bs):\n",
    "            y_pred, y_ = pred[img_i], y[img_i]\n",
    "            for j, metric in enumerate(metrics):\n",
    "                metrics_vals[c, j] = metric.eval(torch.stack([y_pred]), torch.stack([y_]))\n",
    "                                    \n",
    "            if save_images_every > 0 and c % save_images_every == 0:\n",
    "                saved_images_pred[img_c] = y_pred.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                saved_images_true[img_c] = y_.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "                img_c += 1\n",
    "                \n",
    "            c += 1\n",
    "                  \n",
    "        if i % max((dataset_len//10),1) == 0 or i == dataset_len -1:\n",
    "            s = \"\"\n",
    "\n",
    "            for i,metric in enumerate(metrics):\n",
    "                if metric.average:\n",
    "                    s += f\"{metric.name}={np.mean(metrics_vals[:(c-1), i])} ; \"\n",
    "\n",
    "            pbar.set_description(f\"examples seen so far : {c} \" + s)\n",
    " \n",
    "    ret = {}\n",
    "    \n",
    "    for i,metric in enumerate(metrics):\n",
    "        ret[metric.name] = metrics_vals[:, i]   \n",
    "        \n",
    "    if save_images_every > 0:\n",
    "        ret[\"img_pred\"] = saved_images_pred\n",
    "        ret[\"img_true\"] = saved_images_true\n",
    "    \n",
    "    return ret \n",
    "\n",
    "def report_metrics_task2(results : Dict, epoch : int, metrics : List[Metric], WANDB_ON : bool = True, prefix=\"val\", run=None) -> Dict:\n",
    "    \n",
    "    ret = {}\n",
    "    for metric in metrics:\n",
    "        if metric.average:\n",
    "            avg = np.average(results[metric.name])\n",
    "            name_to_save = f\"{prefix}_{metric.name}\"\n",
    "            ret[name_to_save] = avg\n",
    "\n",
    "            if WANDB_ON:\n",
    "                wandb.log({name_to_save : avg})\n",
    "    \n",
    "    if \"img_pred\" in results and \"img_true\" in results:\n",
    "        size = results[\"img_pred\"].shape\n",
    "        imgs = []\n",
    "        \n",
    "        for b in range(size[0]):\n",
    "            img = np.concatenate([results[\"img_pred\"][b], results[\"img_true\"][b]], axis=1)\n",
    "            img_to_save = wandb.Image(img, caption=\"Left: predicted, right : true\")\n",
    "            wandb.log({f\"Epoch={epoch}\" : img_to_save})\n",
    "            \n",
    "    return ret\n",
    " \n",
    "def run_experiment_task2(train_dataloader : torch.utils.data.DataLoader,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
